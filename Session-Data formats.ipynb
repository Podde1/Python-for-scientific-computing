{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d826af32-2a69-4ccf-8e10-c6162817b715",
   "metadata": {},
   "source": [
    "## Data formats with Pandas and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33891f5a-ae29-46a3-88e9-2db91f69f04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   string     100000 non-null  object        \n",
      " 1   timestamp  100000 non-null  datetime64[ns]\n",
      " 2   integer    100000 non-null  int32         \n",
      " 3   float      100000 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int32(1), object(1)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n_rows = 100000\n",
    "\n",
    "dataset = pd.DataFrame(\n",
    "    data={\n",
    "        'string': np.random.choice(('apple', 'banana', 'carrot'), size=n_rows),\n",
    "        'timestamp': pd.date_range(\"20130101\", periods=n_rows, freq=\"s\"),\n",
    "        'integer': np.random.choice(range(0,10), size=n_rows),\n",
    "        'float': np.random.uniform(size=n_rows),\n",
    "    },\n",
    ")\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7075913-1ef0-4ff7-aace-f192a205ba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (1000, 1000)\n",
      "strides:  (8000, 8)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  True\n",
      "fortran:  False\n",
      "data pointer: 0x23df9bb6040\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "data_array = np.random.uniform(size=(n,n))\n",
    "np.info(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078c3d2f-2846-4945-9c66-72a6842e6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data_array.pickle', 'wb') as f:\n",
    "    pickle.dump(data_array, f)\n",
    "\n",
    "with open('data_array.pickle', 'rb') as f:\n",
    "    data_array_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cdb4f9-853e-4cb5-831e-0f345f6a322e",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd89ce45-08ec-4556-81fc-8593500ad861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is string this is string\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "test = 'this is string'\n",
    "with open('teststring.pickle', 'wb') as f:\n",
    "    pickle.dump(test, f)\n",
    "\n",
    "with open('teststring.pickle', 'rb') as f:\n",
    "    teststring_pickle = pickle.load(f)\n",
    "\n",
    "print(test, teststring_pickle)\n",
    "print(test == teststring_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fb461-dcc2-4420-a2dc-64e5c1a5e608",
   "metadata": {},
   "source": [
    "## Storing tidy data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4075bc6-1878-4c5e-90ae-a61797d9643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('dataset.csv', index=False)\n",
    "\n",
    "dataset_csv = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717932c6-a137-451f-9f84-09e33975840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data_array.csv', data_array)\n",
    "\n",
    "data_array_csv = np.loadtxt('data_array.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4167de63-bf48-4b57-b320-a85c7c9d45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_feather('dataset.feather')\n",
    "dataset_feather = pd.read_feather('dataset.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4fc0773-f867-4b68-8bb0-6313e0f56520",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_parquet('dataset.parquet')\n",
    "dataset_parquet = pd.read_parquet('dataset.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e6200-b90d-4142-b99c-8ceba1147e2f",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a3104a-c213-46ac-afe4-40d973e39982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n_rows = 100000\n",
    "\n",
    "dataset = pd.DataFrame(\n",
    "    data={\n",
    "        'string': np.random.choice(('apple', 'banana', 'carrot'), size=n_rows),\n",
    "        'timestamp': pd.date_range(\"20130101\", periods=n_rows, freq=\"s\"),\n",
    "        'integer': np.random.choice(range(0,10), size=n_rows),\n",
    "        'float': np.random.uniform(size=n_rows),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3775d727-5996-48b6-b813-90f535ee3e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          float          \n",
      "           self     other\n",
      "0      0.270126  0.270126\n",
      "3      0.371348  0.371348\n",
      "4      0.023318  0.023318\n",
      "5      0.442812  0.442812\n",
      "7      0.020375  0.020375\n",
      "...         ...       ...\n",
      "99987  0.192471  0.192471\n",
      "99990  0.957900  0.957900\n",
      "99992  0.262314  0.262314\n",
      "99995  0.113735  0.113735\n",
      "99996  0.046833  0.046833\n",
      "\n",
      "[36244 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset.to_csv('dataset.csv', index=False)\n",
    "\n",
    "dataset_csv = pd.read_csv('dataset.csv')\n",
    "\n",
    "print(dataset.compare(dataset_csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab2d6b8-359a-4a9a-9226-9b3c99c6cb03",
   "metadata": {},
   "source": [
    "## Storing array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfbd2d45-8ec2-45f8-b9c4-8e930987d208",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data_array.npy', data_array)\n",
    "data_array_npy = np.load('data_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b23bcd64-de0d-48ef-a2b9-49ca3947c8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27947882, 0.43673478, 0.60732861, ..., 0.4466572 , 0.58437816,\n",
       "        0.44634046],\n",
       "       [0.19893867, 0.37120525, 0.88987245, ..., 0.74517748, 0.94108994,\n",
       "        0.4918413 ],\n",
       "       [0.1270019 , 0.81074491, 0.80777276, ..., 0.50451509, 0.21498927,\n",
       "        0.99134728],\n",
       "       ...,\n",
       "       [0.24713794, 0.63883172, 0.94980864, ..., 0.37222326, 0.30727534,\n",
       "        0.08626338],\n",
       "       [0.75021352, 0.71982179, 0.72187804, ..., 0.47907573, 0.80351434,\n",
       "        0.13792698],\n",
       "       [0.9627765 , 0.10380325, 0.44014827, ..., 0.68165828, 0.41728566,\n",
       "        0.98563194]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.savez('data_arrays.npz', data_array0=data_array, data_array1=data_array)\n",
    "data_arrays = np.load('data_arrays.npz')\n",
    "data_arrays['data_array0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370667a3-8b39-4ce8-8ba0-cd6c21ff95d6",
   "metadata": {},
   "source": [
    "## HDF5 (Hierarchical Data Format version 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de2c4d0e-6846-44b2-b6d0-9eae83cb2c64",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pytables'.  Use pip or conda to install pytables.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\pandas\\compat\\_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tables'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_hdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m dataset_hdf5 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_hdf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\pandas\\core\\generic.py:2799\u001b[0m, in \u001b[0;36mNDFrame.to_hdf\u001b[1;34m(self, path_or_buf, key, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m   2795\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pytables\n\u001b[0;32m   2797\u001b[0m \u001b[38;5;66;03m# Argument 3 to \"to_hdf\" has incompatible type \"NDFrame\"; expected\u001b[39;00m\n\u001b[0;32m   2798\u001b[0m \u001b[38;5;66;03m# \"Union[DataFrame, Series]\" [arg-type]\u001b[39;00m\n\u001b[1;32m-> 2799\u001b[0m \u001b[43mpytables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_hdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   2803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2807\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_itemsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_itemsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2815\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\pandas\\io\\pytables.py:298\u001b[0m, in \u001b[0;36mto_hdf\u001b[1;34m(path_or_buf, key, value, mode, complevel, complib, append, format, index, min_itemsize, nan_rep, dropna, data_columns, errors, encoding)\u001b[0m\n\u001b[0;32m    296\u001b[0m path_or_buf \u001b[38;5;241m=\u001b[39m stringify_path(path_or_buf)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mHDFStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomplib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplib\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m store:\n\u001b[0;32m    301\u001b[0m         f(store)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\pandas\\io\\pytables.py:559\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat is not a defined argument for HDFStore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 559\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtables\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m complib \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tables\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mall_complibs:\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplib only supports \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtables\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;241m.\u001b[39mall_complibs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m compression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\pandas\\compat\\_optional.py:144\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pytables'.  Use pip or conda to install pytables."
     ]
    }
   ],
   "source": [
    "dataset.to_hdf('dataset.h5', key='dataset', mode='w')\n",
    "dataset_hdf5 = pd.read_hdf('dataset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c124057-8219-4a89-92ca-15103a23d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Writing:\n",
    "\n",
    "# Open HDF5 file\n",
    "h5_file = h5py.File('data_array.h5', 'w')\n",
    "# Write dataset\n",
    "h5_file.create_dataset('data_array', data=data_array)\n",
    "# Close file and write data to disk. Important!\n",
    "h5_file.close()\n",
    "\n",
    "# Reading:\n",
    "\n",
    "# Open HDF5 file again\n",
    "h5_file = h5py.File('data_array.h5', 'r')\n",
    "# Read the full dataset\n",
    "data_array_h5 = h5_file['data_array'][()]\n",
    "# Close file\n",
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b426d18-66c2-447a-9c13-a91b03770c09",
   "metadata": {},
   "source": [
    "## NetCDF4 (Network Common Data Form version 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "264eb1d0-4945-4099-8bc7-8e57a0d44381",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine h5netcdf must be one of: ['store']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read tidy data from NetCDF4\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dataset_xarray \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh5netcdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m dataset_netcdf4 \u001b[38;5;241m=\u001b[39m dataset_xarray\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[0;32m      7\u001b[0m dataset_xarray\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\xarray\\backends\\api.py:525\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    523\u001b[0m     engine \u001b[38;5;241m=\u001b[39m plugins\u001b[38;5;241m.\u001b[39mguess_engine(filename_or_obj)\n\u001b[1;32m--> 525\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[0;32m    528\u001b[0m     decode_cf,\n\u001b[0;32m    529\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    536\u001b[0m )\n\u001b[0;32m    538\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\xarray\\backends\\plugins.py:185\u001b[0m, in \u001b[0;36mget_backend\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m    183\u001b[0m     engines \u001b[38;5;241m=\u001b[39m list_engines()\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         )\n\u001b[0;32m    188\u001b[0m     backend \u001b[38;5;241m=\u001b[39m engines[engine]\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(engine, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(engine, BackendEntrypoint):\n",
      "\u001b[1;31mValueError\u001b[0m: unrecognized engine h5netcdf must be one of: ['store']"
     ]
    }
   ],
   "source": [
    "# Write tidy data as NetCDF4\n",
    "dataset.to_xarray().to_netcdf('dataset.nc', engine='h5netcdf')\n",
    "# Read tidy data from NetCDF4\n",
    "import xarray as xr\n",
    "dataset_xarray = xr.open_dataset('dataset.nc', engine='h5netcdf')\n",
    "dataset_netcdf4 = dataset_xarray.to_pandas()\n",
    "dataset_xarray.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46632248-cc7c-4e5c-9bdd-217b7d6f8698",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unrecognized engine h5netcdf must be one of: ['store']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m xr\u001b[38;5;241m.\u001b[39mDataArray(data_array)\u001b[38;5;241m.\u001b[39mto_netcdf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_array.nc\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read array data from NetCDF4\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data_array_xarray \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_array.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh5netcdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m data_array_netcdf4 \u001b[38;5;241m=\u001b[39m data_array_xarray\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      6\u001b[0m data_array_xarray\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\xarray\\backends\\api.py:700\u001b[0m, in \u001b[0;36mopen_dataarray\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataarray\u001b[39m(\n\u001b[0;32m    561\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataArray:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;124;03m\"\"\"Open an DataArray from a file or file-like object containing a single\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    data variable.\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;124;03m    open_dataset\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 700\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m open_dataset(\n\u001b[0;32m    701\u001b[0m         filename_or_obj,\n\u001b[0;32m    702\u001b[0m         decode_cf\u001b[38;5;241m=\u001b[39mdecode_cf,\n\u001b[0;32m    703\u001b[0m         mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[0;32m    704\u001b[0m         decode_times\u001b[38;5;241m=\u001b[39mdecode_times,\n\u001b[0;32m    705\u001b[0m         concat_characters\u001b[38;5;241m=\u001b[39mconcat_characters,\n\u001b[0;32m    706\u001b[0m         decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    707\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    708\u001b[0m         chunks\u001b[38;5;241m=\u001b[39mchunks,\n\u001b[0;32m    709\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache,\n\u001b[0;32m    710\u001b[0m         drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[0;32m    711\u001b[0m         inline_array\u001b[38;5;241m=\u001b[39minline_array,\n\u001b[0;32m    712\u001b[0m         backend_kwargs\u001b[38;5;241m=\u001b[39mbackend_kwargs,\n\u001b[0;32m    713\u001b[0m         use_cftime\u001b[38;5;241m=\u001b[39muse_cftime,\n\u001b[0;32m    714\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[0;32m    715\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    716\u001b[0m     )\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mdata_vars) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    720\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven file dataset contains more than one data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    721\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable. Please read with xarray.open_dataset and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthen select the variable you want.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m         )\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\xarray\\backends\\api.py:525\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    523\u001b[0m     engine \u001b[38;5;241m=\u001b[39m plugins\u001b[38;5;241m.\u001b[39mguess_engine(filename_or_obj)\n\u001b[1;32m--> 525\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[0;32m    528\u001b[0m     decode_cf,\n\u001b[0;32m    529\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    536\u001b[0m )\n\u001b[0;32m    538\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\Projects\\Python course HT2022\\venv\\lib\\site-packages\\xarray\\backends\\plugins.py:185\u001b[0m, in \u001b[0;36mget_backend\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m    183\u001b[0m     engines \u001b[38;5;241m=\u001b[39m list_engines()\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m engines:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(engines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         )\n\u001b[0;32m    188\u001b[0m     backend \u001b[38;5;241m=\u001b[39m engines[engine]\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(engine, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(engine, BackendEntrypoint):\n",
      "\u001b[1;31mValueError\u001b[0m: unrecognized engine h5netcdf must be one of: ['store']"
     ]
    }
   ],
   "source": [
    "# Write array data as NetCDF4\n",
    "xr.DataArray(data_array).to_netcdf('data_array.nc', engine='h5netcdf')\n",
    "# Read array data from NetCDF4\n",
    "data_array_xarray = xr.open_dataarray('data_array.nc', engine='h5netcdf')\n",
    "data_array_netcdf4 = data_array_xarray.to_numpy()\n",
    "data_array_xarray.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a32325-bced-42d5-9493-0b99c6bee142",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8c7a3c3-0d15-4ea6-ab2c-0539b04c0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "data_array = np.random.uniform(size=(n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b67016d-9f77-4a9a-b5cd-66b81d60b58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('data_array.npy', data_array)\n",
    "data_array_npy = np.load('data_array.npy')\n",
    "np.all(data_array == data_array_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8721-b408-48b8-aa85-681ae35d911a",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "767d8c98-5929-481b-a99a-6c647eca3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_json('dataset.json')\n",
    "dataset_json = pd.read_json('dataset.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
